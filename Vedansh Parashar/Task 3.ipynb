{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5211f7d6-a946-4beb-8928-89115be180a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\vedan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\vedan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\vedan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\vedan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from collections import Counter\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3633d9d-e423-4e0d-8e0c-fb43cb38fdbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replace this path if needed\n",
    "df = pd.read_csv(\"IMDB Dataset.csv\")\n",
    "\n",
    "# View sample\n",
    "df.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39578b72-87e9-4056-9e61-742e2ca94214",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['reviewers',\n",
       " 'mentioned',\n",
       " 'watching',\n",
       " 'oz',\n",
       " 'episode',\n",
       " 'youll',\n",
       " 'hooked',\n",
       " 'right',\n",
       " 'exactly',\n",
       " 'happened',\n",
       " 'first',\n",
       " 'thing',\n",
       " 'struck',\n",
       " 'oz',\n",
       " 'brutality',\n",
       " 'unflinching',\n",
       " 'scenes',\n",
       " 'violence',\n",
       " 'set',\n",
       " 'right',\n",
       " 'word',\n",
       " 'go',\n",
       " 'trust',\n",
       " 'show',\n",
       " 'faint',\n",
       " 'hearted',\n",
       " 'timid',\n",
       " 'show',\n",
       " 'pulls',\n",
       " 'punches',\n",
       " 'regards',\n",
       " 'drugs',\n",
       " 'sex',\n",
       " 'violence',\n",
       " 'hardcore',\n",
       " 'classic',\n",
       " 'use',\n",
       " 'word',\n",
       " 'called',\n",
       " 'oz',\n",
       " 'nickname',\n",
       " 'given',\n",
       " 'oswald',\n",
       " 'maximum',\n",
       " 'security',\n",
       " 'state',\n",
       " 'penitentary',\n",
       " 'focuses',\n",
       " 'mainly',\n",
       " 'emerald',\n",
       " 'city',\n",
       " 'experimental',\n",
       " 'section',\n",
       " 'prison',\n",
       " 'cells',\n",
       " 'glass',\n",
       " 'fronts',\n",
       " 'face',\n",
       " 'inwards',\n",
       " 'privacy',\n",
       " 'high',\n",
       " 'agenda',\n",
       " 'em',\n",
       " 'city',\n",
       " 'home',\n",
       " 'manyaryans',\n",
       " 'muslims',\n",
       " 'gangstas',\n",
       " 'latinos',\n",
       " 'christians',\n",
       " 'italians',\n",
       " 'irish',\n",
       " 'moreso',\n",
       " 'scuffles',\n",
       " 'death',\n",
       " 'stares',\n",
       " 'dodgy',\n",
       " 'dealings',\n",
       " 'shady',\n",
       " 'agreements',\n",
       " 'never',\n",
       " 'far',\n",
       " 'away',\n",
       " 'would',\n",
       " 'say',\n",
       " 'main',\n",
       " 'appeal',\n",
       " 'show',\n",
       " 'due',\n",
       " 'fact',\n",
       " 'goes',\n",
       " 'shows',\n",
       " 'wouldnt',\n",
       " 'dare',\n",
       " 'forget',\n",
       " 'pretty',\n",
       " 'pictures',\n",
       " 'painted',\n",
       " 'mainstream',\n",
       " 'audiences',\n",
       " 'forget',\n",
       " 'charm',\n",
       " 'forget',\n",
       " 'romanceoz',\n",
       " 'doesnt',\n",
       " 'mess',\n",
       " 'around',\n",
       " 'first',\n",
       " 'episode',\n",
       " 'ever',\n",
       " 'saw',\n",
       " 'struck',\n",
       " 'nasty',\n",
       " 'surreal',\n",
       " 'couldnt',\n",
       " 'say',\n",
       " 'ready',\n",
       " 'watched',\n",
       " 'developed',\n",
       " 'taste',\n",
       " 'oz',\n",
       " 'got',\n",
       " 'accustomed',\n",
       " 'high',\n",
       " 'levels',\n",
       " 'graphic',\n",
       " 'violence',\n",
       " 'violence',\n",
       " 'injustice',\n",
       " 'crooked',\n",
       " 'guards',\n",
       " 'wholl',\n",
       " 'sold',\n",
       " 'nickel',\n",
       " 'inmates',\n",
       " 'wholl',\n",
       " 'kill',\n",
       " 'order',\n",
       " 'get',\n",
       " 'away',\n",
       " 'well',\n",
       " 'mannered',\n",
       " 'middle',\n",
       " 'class',\n",
       " 'inmates',\n",
       " 'turned',\n",
       " 'prison',\n",
       " 'bitches',\n",
       " 'due',\n",
       " 'lack',\n",
       " 'street',\n",
       " 'skills',\n",
       " 'prison',\n",
       " 'experience',\n",
       " 'watching',\n",
       " 'oz',\n",
       " 'may',\n",
       " 'become',\n",
       " 'comfortable',\n",
       " 'uncomfortable',\n",
       " 'viewingthats',\n",
       " 'get',\n",
       " 'touch',\n",
       " 'darker',\n",
       " 'side']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create custom stopwords list\n",
    "custom_stopwords = set(stopwords.words('english'))\n",
    "extra_words = {\"movie\", \"film\", \"one\", \"make\", \"character\", \"like\"}\n",
    "custom_stopwords.update(extra_words)\n",
    "\n",
    "# Cleaning function\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"<.*?>\", \" \", text)\n",
    "    text = re.sub(r\"[^a-z\\s]\", \"\", text)\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [t for t in tokens if t not in custom_stopwords and len(t) > 1]\n",
    "    return tokens\n",
    "\n",
    "# Apply cleaning\n",
    "df['cleaned'] = df['review'].apply(clean_text)\n",
    "\n",
    "# View cleaned tokens\n",
    "df['cleaned'].iloc[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dabd71d-c0ab-4169-a03e-11cf2170c4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying Stemming and Lemmatization\n",
    "stemmer = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Apply stemming\n",
    "df['stemmed'] = df['cleaned'].apply(lambda tokens: [stemmer.stem(t) for t in tokens])\n",
    "\n",
    "# Apply lemmatization\n",
    "df['lemmatized'] = df['cleaned'].apply(lambda tokens: [lemmatizer.lemmatize(t) for t in tokens])\n",
    "\n",
    "# Sample outputs\n",
    "print(\"Stemmed:\", df['stemmed'].iloc[0])\n",
    "print(\"Lemmatized:\", df['lemmatized'].iloc[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87373c45-a9c3-4b46-aa25-e7bf68888b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vocabulary Size Comparison\n",
    "stemmed_vocab = set([word for tokens in df['stemmed'] for word in tokens])\n",
    "lemm_vocab = set([word for tokens in df['lemmatized'] for word in tokens])\n",
    "\n",
    "print(\"Vocabulary size after stemming:\", len(stemmed_vocab))\n",
    "print(\"Vocabulary size after lemmatization:\", len(lemm_vocab))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a012f2ec-785c-4b68-8559-5b067159b0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bar Plots â€“ Top 30 Frequent Words\n",
    "def plot_top_words(tokens_list, title):\n",
    "    all_words = [word for tokens in tokens_list for word in tokens]\n",
    "    word_freq = Counter(all_words).most_common(30)\n",
    "    words, counts = zip(*word_freq)\n",
    "    \n",
    "    plt.figure(figsize=(12,6))\n",
    "    plt.bar(words, counts, color='orange')\n",
    "    plt.title(title)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_top_words(df['stemmed'], \"Top 30 Words - Stemming\")\n",
    "plot_top_words(df['lemmatized'], \"Top 30 Words - Lemmatization\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f0bdf3-45b6-4bf0-a513-bfbcb48608ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Word Clouds\n",
    "def show_wordcloud(tokens_list, title):\n",
    "    text = ' '.join([' '.join(tokens) for tokens in tokens_list])\n",
    "    wordcloud = WordCloud(width=800, height=400, background_color='white').generate(text)\n",
    "    \n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.imshow(wordcloud, interpolation='bilinear')\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "show_wordcloud(df['stemmed'], \"Word Cloud - Stemming\")\n",
    "show_wordcloud(df['lemmatized'], \"Word Cloud - Lemmatization\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70638a40-3aaf-47a0-8e69-9200639806ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analysis Summary\n",
    "print(\"----- Analysis Summary -----\\n\")\n",
    "print(\"1. Stemming yields a smaller vocabulary by aggressively trimming word forms.\")\n",
    "print(\"2. Lemmatization retains more context and yields human-readable words.\")\n",
    "print(\"3. Bar plots and word clouds confirm that lemmatized results are semantically richer.\")\n",
    "print(\"4. Use stemming when performance matters more than interpretability.\")\n",
    "print(\"5. Use lemmatization for better accuracy in downstream NLP tasks.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9125829e-3523-4ebf-8f01-f9c2067ce164",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
